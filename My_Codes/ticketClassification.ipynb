{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'instructor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# --------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Customer Support Ticket Classification System\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# --------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minstructor\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Field\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'instructor'"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Customer Support Ticket Classification System\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "import instructor\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "from enum import Enum\n",
    "from typing import List\n",
    "\n",
    "# Sample customer support tickets\n",
    "ticket1 = \"\"\"\n",
    "I ordered a laptop from your store last week (Order #12345), but I received a tablet instead. \n",
    "This is unacceptable! I need the laptop for work urgently. Please resolve this immediately or I'll have to dispute the charge.\n",
    "\"\"\"\n",
    "\n",
    "ticket2 = \"\"\"\n",
    "Hello, I'm having trouble logging into my account. I've tried resetting my password, but I'm not receiving the reset email. \n",
    "Can you please help me regain access to my account? I've been a loyal customer for years and have several pending orders.\n",
    "\"\"\"\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Regular Completion using OpenAI (with drawbacks)\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def classify_ticket_simple(ticket_text: str) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Classify the following customer support ticket into a category.\"},\n",
    "            {\"role\": \"user\", \"content\": ticket_text}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "result = classify_ticket_simple(ticket1)\n",
    "print(result)\n",
    "\n",
    "\"\"\"\n",
    "Drawbacks of this approach:\n",
    "1. No structured output, making it difficult to integrate into automated systems\n",
    "2. No validation of the output, potentially leading to inconsistent categorizations\n",
    "3. Limited information extracted, missing important details for prioritization\n",
    "4. No confidence score, making it hard to flag uncertain classifications for human review\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 1: Get clear on your objectives\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "\"\"\"\n",
    "Objective: Develop an AI-powered ticket classification system that:\n",
    "- Accurately categorizes customer support tickets\n",
    "- Assesses the urgency and sentiment of each ticket\n",
    "- Extracts key information for quick resolution\n",
    "- Provides confidence scores to flag uncertain cases for human review\n",
    "Business impact:\n",
    "- Reduce average response time by routing tickets to the right department\n",
    "- Improve customer satisfaction by prioritizing urgent and negative sentiment tickets\n",
    "- Increase efficiency by providing agents with key information upfront\n",
    "- Optimize workforce allocation by automating routine classifications\n",
    "\"\"\"\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 2: Patch your LLM with instructor\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# Instructor makes it easy to get structured data like JSON from LLMs\n",
    "client = instructor.patch(OpenAI())\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 3: Define Pydantic data models\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "\"\"\"\n",
    "This code defines a structured data model for classifying customer support tickets using Pydantic and Python's Enum class. \n",
    "It specifies categories, urgency levels, customer sentiments, and other relevant information as predefined options or constrained fields. \n",
    "This structure ensures data consistency, enables automatic validation, and facilitates easy integration with AI models and other parts of a support ticket system.\n",
    "\"\"\"\n",
    "\n",
    "class TicketCategory(str, Enum):\n",
    "    ORDER_ISSUE = \"order_issue\"\n",
    "    ACCOUNT_ACCESS = \"account_access\"\n",
    "    PRODUCT_INQUIRY = \"product_inquiry\"\n",
    "    TECHNICAL_SUPPORT = \"technical_support\"\n",
    "    BILLING = \"billing\"\n",
    "    OTHER = \"other\"\n",
    "\n",
    "class CustomerSentiment(str, Enum):\n",
    "    ANGRY = \"angry\"\n",
    "    FRUSTRATED = \"frustrated\"\n",
    "    NEUTRAL = \"neutral\"\n",
    "    SATISFIED = \"satisfied\"\n",
    "\n",
    "class TicketUrgency(str, Enum):\n",
    "    LOW = \"low\"\n",
    "    MEDIUM = \"medium\"\n",
    "    HIGH = \"high\"\n",
    "    CRITICAL = \"critical\"\n",
    "\n",
    "class TicketClassification(BaseModel):\n",
    "    category: TicketCategory\n",
    "    urgency: TicketUrgency\n",
    "    sentiment: CustomerSentiment\n",
    "    confidence: float = Field(ge=0, le=1, description=\"Confidence score for the classification\")\n",
    "    key_information: List[str] = Field(description=\"List of key points extracted from the ticket\")\n",
    "    suggested_action: str = Field(description=\"Brief suggestion for handling the ticket\")\n",
    "    \n",
    "    \n",
    "ticket_classification = TicketClassification(\n",
    "    category=TicketCategory.ORDER_ISSUE,\n",
    "    urgency=TicketUrgency.HIGH,\n",
    "    sentiment=CustomerSentiment.ANGRY,\n",
    "    confidence=0.9,\n",
    "    key_information=[\"Order #12345\", \"Received tablet instead of laptop\"],\n",
    "    suggested_action=\"Contact customer to arrange laptop delivery\"\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 4: Bring everything together in a single function\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "def classify_ticket(ticket_text: str) -> TicketClassification:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        response_model=TicketClassification,\n",
    "        temperature=0,\n",
    "        max_retries=3,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Analyze the following customer support ticket and extract the requested information.\"\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": ticket_text}\n",
    "        ]\n",
    "    )\n",
    "    return response\n",
    "\n",
    "result1 = classify_ticket(ticket1)\n",
    "result2 = classify_ticket(ticket2)\n",
    "\n",
    "print(result1.model_dump_json(indent=2))\n",
    "print(result2.model_dump_json(indent=2))\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 5: Optimize your prompts and experiment\n",
    "# --------------------------------------------------------------\n",
    "# To optimize:\n",
    "# 1. Refine the system message to provide more context about your business\n",
    "# 2. Experiment with different models (e.g., gpt-3.5-turbo vs gpt-4)\n",
    "# 3. Fine-tune the model on your specific ticket data if available\n",
    "# 4. Adjust the TicketClassification model based on business needs\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an AI assistant for a large e-commerce platform's customer support team. \n",
    "Your role is to analyze incoming customer support tickets and provide structured information to help our team respond quickly and effectively.\n",
    "Business Context:\n",
    "- We handle thousands of tickets daily across various categories (orders, accounts, products, technical issues, billing).\n",
    "- Quick and accurate classification is crucial for customer satisfaction and operational efficiency.\n",
    "- We prioritize based on urgency and customer sentiment.\n",
    "Your tasks:\n",
    "1. Categorize the ticket into the most appropriate category.\n",
    "2. Assess the urgency of the issue (low, medium, high, critical).\n",
    "3. Determine the customer's sentiment.\n",
    "4. Extract key information that would be helpful for our support team.\n",
    "5. Suggest an initial action for handling the ticket.\n",
    "6. Provide a confidence score for your classification.\n",
    "Remember:\n",
    "- Be objective and base your analysis solely on the information provided in the ticket.\n",
    "- If you're unsure about any aspect, reflect that in your confidence score.\n",
    "- For 'key_information', extract specific details like order numbers, product names, or account issues.\n",
    "- The 'suggested_action' should be a brief, actionable step for our support team.\n",
    "Analyze the following customer support ticket and provide the requested information in the specified format.\n",
    "\"\"\"\n",
    "\n",
    "def classify_ticket(ticket_text: str) -> TicketClassification:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_model=TicketClassification,\n",
    "        temperature=0,\n",
    "        max_retries=3,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": SYSTEM_PROMPT,\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": ticket_text}\n",
    "        ]\n",
    "    )\n",
    "    return response\n",
    "\n",
    "result1 = classify_ticket(ticket1)\n",
    "result2 = classify_ticket(ticket2)\n",
    "\n",
    "print(result1.model_dump_json(indent=2))\n",
    "print(result2.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting instructorNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Obtaining dependency information for instructor from https://files.pythonhosted.org/packages/c5/82/fd319382c1a33d7021cf151007b4cbd5daddf09d9ca5fb670e476668f9fc/instructor-1.7.2-py3-none-any.whl.metadata\n",
      "  Downloading instructor-1.7.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.9.1 (from instructor)\n",
      "  Obtaining dependency information for aiohttp<4.0.0,>=3.9.1 from https://files.pythonhosted.org/packages/fc/db/2192489a8a51b52e06627506f8ac8df69ee221de88ab9bdea77aa793aa6a/aiohttp-3.11.11-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading aiohttp-3.11.11-cp311-cp311-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting docstring-parser<1.0,>=0.16 (from instructor)\n",
      "  Obtaining dependency information for docstring-parser<1.0,>=0.16 from https://files.pythonhosted.org/packages/d5/7c/e9fcff7623954d86bdc17782036cbf715ecab1bec4847c008557affe1ca8/docstring_parser-0.16-py3-none-any.whl.metadata\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in c:\\users\\m02555\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from instructor) (3.1.4)\n",
      "Collecting jiter<0.9,>=0.6.1 (from instructor)\n",
      "  Obtaining dependency information for jiter<0.9,>=0.6.1 from https://files.pythonhosted.org/packages/4e/1e/7f96b798f356e531ffc0f53dd2f37185fac60fae4d6c612bbbd4639b90aa/jiter-0.8.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading jiter-0.8.2-cp311-cp311-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting openai<2.0.0,>=1.52.0 (from instructor)\n",
      "  Obtaining dependency information for openai<2.0.0,>=1.52.0 from https://files.pythonhosted.org/packages/6d/47/7b92f1731c227f4139ef0025b5996062e44f9a749c54315c8bdb34bad5ec/openai-1.59.7-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.59.7-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in c:\\users\\m02555\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from instructor) (2.27.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.8.0 in c:\\users\\m02555\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from instructor) (2.10.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in c:\\users\\m02555\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from instructor) (2.32.3)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.7.0 in c:\\users\\m02555\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from instructor) (13.7.1)\n",
      "Collecting tenacity<10.0.0,>=9.0.0 (from instructor)\n",
      "  Obtaining dependency information for tenacity<10.0.0,>=9.0.0 from https://files.pythonhosted.org/packages/b6/cb/b86984bed139586d01532a587464b5805f12e397594f19f931c4c2fbfa61/tenacity-9.0.0-py3-none-any.whl.metadata\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.9.0 in c:\\users\\m02555\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from instructor) (0.12.3)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.9.1->instructor)\n",
      "  Obtaining dependency information for aiohappyeyeballs>=2.3.0 from https://files.pythonhosted.org/packages/b9/74/fbb6559de3607b3300b9be3cc64e97548d55678e44623db17820dbd20002/aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.9.1->instructor)\n",
      "  Obtaining dependency information for aiosignal>=1.1.2 from https://files.pythonhosted.org/packages/ec/6a/bc7e17a3e87a2985d3e8f4da4cd0f481060eb78fb08596c42be62c90a4d9/aiosignal-1.3.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\m02555\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.9.1->instructor)\n",
      "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/ca/8c/2ddffeb8b60a4bce3b196c32fcc30d8830d4615e7b492ec2071da801b8ad/frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.9.1->instructor)\n",
      "  Obtaining dependency information for multidict<7.0,>=4.5 from https://files.pythonhosted.org/packages/9f/0b/ad879847ecbf6d27e90a6eabb7eff6b62c129eefe617ea45eae7c1f0aead/multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.9.1->instructor)\n",
      "  Obtaining dependency information for propcache>=0.2.0 from https://files.pythonhosted.org/packages/cf/59/7cc7037b295d5772eceb426358bb1b86e6cab4616d971bd74275395d100d/propcache-0.2.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading propcache-0.2.1-cp311-cp311-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.9.1->instructor)\n",
      "  Obtaining dependency information for yarl<2.0,>=1.17.0 from https://files.pythonhosted.org/packages/ae/7b/8600250b3d89b625f1121d897062f629883c2f45339623b69b1747ec65fa/yarl-1.18.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading yarl-1.18.3-cp311-cp311-win_amd64.whl.metadata (71 kB)\n",
      "     ---------------------------------------- 0.0/71.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 71.4/71.4 kB ? eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\m02555\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2<4.0.0,>=3.1.4->instructor) (2.1.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\m02555\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.52.0->instructor) (4.8.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.52.0->instructor)\n",
      "  Obtaining dependency information for distro<2,>=1.7.0 from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\m02555\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.52.0->instructor) (0.27.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\m02555\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.52.0->instructor) (1.3.0)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.52.0->instructor)\n",
      "  Obtaining dependency information for tqdm>4 from https://files.pythonhosted.org/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.7/57.7 kB ? eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\m02555\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.52.0->instructor) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\m02555\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.8.0->instructor) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\m02555\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.32.3->instructor) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\m02555\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.32.3->instructor) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\m02555\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.32.3->instructor) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\m02555\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.32.3->instructor) (2023.7.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\m02555\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich<14.0.0,>=13.7.0->instructor) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\m02555\\appdata\\roaming\\python\\python311\\site-packages (from rich<14.0.0,>=13.7.0->instructor) (2.16.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\m02555\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0.0,>=0.9.0->instructor) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\m02555\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0.0,>=0.9.0->instructor) (1.5.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\m02555\\appdata\\roaming\\python\\python311\\site-packages (from click>=8.0.0->typer<1.0.0,>=0.9.0->instructor) (0.4.6)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\m02555\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->instructor) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\m02555\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->instructor) (0.14.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\m02555\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->instructor) (0.1.2)\n",
      "Downloading instructor-1.7.2-py3-none-any.whl (71 kB)\n",
      "   ---------------------------------------- 0.0/71.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 71.4/71.4 kB ? eta 0:00:00\n",
      "Downloading aiohttp-3.11.11-cp311-cp311-win_amd64.whl (442 kB)\n",
      "   ---------------------------------------- 0.0/442.5 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 143.4/442.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 442.5/442.5 kB 5.5 MB/s eta 0:00:00\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading jiter-0.8.2-cp311-cp311-win_amd64.whl (206 kB)\n",
      "   ---------------------------------------- 0.0/206.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 206.7/206.7 kB 12.3 MB/s eta 0:00:00\n",
      "Downloading openai-1.59.7-py3-none-any.whl (454 kB)\n",
      "   ---------------------------------------- 0.0/454.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 454.8/454.8 kB 14.3 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "   ---------------------------------------- 0.0/51.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 51.6/51.6 kB 2.6 MB/s eta 0:00:00\n",
      "Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading propcache-0.2.1-cp311-cp311-win_amd64.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.4/44.4 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.5/78.5 kB ? eta 0:00:00\n",
      "Downloading yarl-1.18.3-cp311-cp311-win_amd64.whl (91 kB)\n",
      "   ---------------------------------------- 0.0/91.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 91.0/91.0 kB 5.0 MB/s eta 0:00:00\n",
      "Installing collected packages: tqdm, tenacity, propcache, multidict, jiter, frozenlist, docstring-parser, distro, aiohappyeyeballs, yarl, aiosignal, openai, aiohttp, instructor\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.2.3\n",
      "    Uninstalling tenacity-8.2.3:\n",
      "      Successfully uninstalled tenacity-8.2.3\n",
      "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 distro-1.9.0 docstring-parser-0.16 frozenlist-1.5.0 instructor-1.7.2 jiter-0.8.2 multidict-6.1.0 openai-1.59.7 propcache-0.2.1 tenacity-9.0.0 tqdm-4.67.1 yarl-1.18.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'c:\\Users\\M02555\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script distro.exe is installed in 'c:\\Users\\M02555\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script openai.exe is installed in 'c:\\Users\\M02555\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script instructor.exe is installed in 'c:\\Users\\M02555\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install instructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
